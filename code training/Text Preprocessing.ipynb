{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95c3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, time, re, string, ast\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161bc7e",
   "metadata": {},
   "source": [
    "# Read x_train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c65440",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a1= pickle.load(open(\"x_train before prepro\\\\x_train_a1.pickle\", \"rb\"))\n",
    "x_train_s1= pickle.load(open(\"x_train before prepro\\\\x_train_s1.pickle\", \"rb\"))\n",
    "x_train_a2= pickle.load(open(\"x_train before prepro\\\\x_train_a2.pickle\", \"rb\"))\n",
    "x_train_s2= pickle.load(open(\"x_train before prepro\\\\x_train_s2.pickle\", \"rb\"))\n",
    "x_train_a3= pickle.load(open(\"x_train before prepro\\\\x_train_a3.pickle\", \"rb\"))\n",
    "x_train_s3= pickle.load(open(\"x_train before prepro\\\\x_train_s3.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9598dcfd",
   "metadata": {},
   "source": [
    "# Read x_test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454e3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a1= pickle.load(open(\"x_test before prepro\\\\x_test_a1.pickle\", \"rb\"))\n",
    "x_test_s1= pickle.load(open(\"x_test before prepro\\\\x_test_s1.pickle\", \"rb\"))\n",
    "x_test_a2= pickle.load(open(\"x_test before prepro\\\\x_test_a2.pickle\", \"rb\"))\n",
    "x_test_s2= pickle.load(open(\"x_test before prepro\\\\x_test_s2.pickle\", \"rb\"))\n",
    "x_test_a3= pickle.load(open(\"x_test before prepro\\\\x_test_a3.pickle\", \"rb\"))\n",
    "x_test_s3= pickle.load(open(\"x_test before prepro\\\\x_test_s3.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111ca049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file():\n",
    "    # Buka dan baca file 'kamus pre-processing/normalisasi.txt'\n",
    "    with open('kamus pre-processing/normalisasi.txt', encoding=\"utf-8\") as f:\n",
    "        data_normalisai = f.read()\n",
    "    normalization_words = ast.literal_eval(data_normalisai)#Konversi isi file normalisasi menjadi objek Python menggunakan ast.literal_eval()\n",
    "    # Buka dan baca  file 'kamus pre-processing/stopwords.txt'\n",
    "    with open('kamus pre-processing/stopwords.txt') as f:\n",
    "        data_stopwords = f.read()\n",
    "        stopwords = ast.literal_eval(data_stopwords)#Konversi isi file stopwords menjadi objek Python menggunakan ast.literal_eval()\n",
    "\n",
    "    return normalization_words, stopwords\n",
    "\n",
    "normalization_words, stopwords = get_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d13df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(text):\n",
    "    text = text.lower() #ubah teks jadi huruf kecil\n",
    "    return text #Mengembalikan teks yang telah diubah menjadi huruf kecil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4264db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text):\n",
    "    # Menghapus tanda baca dalam teks\n",
    "    for i in text:\n",
    "        if i in list(string.punctuation):\n",
    "            text = text.replace(i, \" \")\n",
    "    # Menghapus angka dalam teks\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    # Menghapus spasi berlebihan di awal dan akhir teks\n",
    "    text = text.strip()\n",
    "     # Menggabungkan spasi berlebihan menjadi satu spasi\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Mengembalikan teks yang telah dibersihkan\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f356f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(texts):\n",
    "    finalText = [] # Membuat list kosong untuk menyimpan teks akhir\n",
    "    splitted_text = texts.split() # Memisahkan teks menjadi kata-kata\n",
    "    for text in splitted_text: # Melakukan iterasi pada setiap kata\n",
    "        if text in normalization_words: # Memeriksa apakah kata tersebut ada dalam kamus normalisasi\n",
    "            finalText.append(normalization_words[text]) # Jika ada, menggantikan kata dengan kata normalisasi yang sesuai\n",
    "        else:\n",
    "            finalText.append(text) # Jika tidak ada, mempertahankan kata asli\n",
    "      \n",
    "    return \" \".join(finalText) # Menggabungkan kata-kata dalam list menjadi satu teks dengan spasi sebagai pemisah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704b05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapus_stopword(text): \n",
    "    stopword_factory = stopwords # Menggunakan stopwords sebagai factory untuk menghapus stopword\n",
    "\n",
    "    sw_dict = ArrayDictionary(stopword_factory) # Membuat dictionary untuk stopword\n",
    "    temp = StopWordRemover(sw_dict) # Membuat objek StopWordRemover dengan dictionary stopword\n",
    "\n",
    "    text = temp.remove(text) # Menghapus stopword dari teks menggunakan StopWordRemover\n",
    "    return text # Mengembalikan teks yang telah dihapus stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57522a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    factory = StemmerFactory() # Membuat objek factory untuk stemming\n",
    "    stemmer = factory.create_stemmer() # Membuat objek stemmer menggunakan factory\n",
    "    text = stemmer.stem(text) # Melakukan proses stemming pada teks menggunakan stemmer\n",
    "    return text # Mengembalikan teks yang telah di-stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e48428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(ulasan):\n",
    "    ulasan = cleansing(ulasan)\n",
    "    ulasan = case_folding(ulasan)\n",
    "    ulasan = normalisasi(ulasan)\n",
    "    ulasan = hapus_stopword(ulasan)\n",
    "    ulasan = stemming(ulasan)\n",
    "    return ulasan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3efc05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a1 = x_train_a1.apply(preprocessing_data); x_test_a1 = x_test_a1.apply(preprocessing_data)\n",
    "x_train_a2 = x_train_a2.apply(preprocessing_data); x_test_a2 = x_test_a2.apply(preprocessing_data)\n",
    "x_train_a3 = x_train_a3.apply(preprocessing_data); x_test_a3 = x_test_a3.apply(preprocessing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0f85ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s1 = x_train_s1.apply(preprocessing_data); x_test_s1 = x_test_s1.apply(preprocessing_data)\n",
    "x_train_s2 = x_train_s2.apply(preprocessing_data); x_test_s2 = x_test_s2.apply(preprocessing_data)\n",
    "x_train_s3 = x_train_s3.apply(preprocessing_data); x_test_s3 = x_test_s3.apply(preprocessing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291e1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dokumentasi Hasil text preprocessing\n",
    "def save_x_train(list_data, f_name):\n",
    "    pickle.dump(list_data, open(\"x_train/\" + f_name + \".pickle\", \"wb\"))\n",
    "\n",
    "save_x_train(x_train_a1, 'x_train_a1')\n",
    "save_x_train(x_train_a2, 'x_train_a2')\n",
    "save_x_train(x_train_a3, 'x_train_a3')\n",
    "\n",
    "save_x_train(x_train_s1, 'x_train_s1')\n",
    "save_x_train(x_train_s2, 'x_train_s2')\n",
    "save_x_train(x_train_s3, 'x_train_s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "112cbeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dokumentasi Hasil text preprocessing\n",
    "def save_x_test(list_data, f_name):\n",
    "    pickle.dump(list_data, open(\"x_test/\" + f_name + \".pickle\", \"wb\"))\n",
    "\n",
    "save_x_test(x_test_a1, 'x_test_a1')\n",
    "save_x_test(x_test_a2, 'x_test_a2')\n",
    "save_x_test(x_test_a3, 'x_test_a3')\n",
    "\n",
    "save_x_test(x_test_s1, 'x_test_s1')\n",
    "save_x_test(x_test_s2, 'x_test_s2')\n",
    "save_x_test(x_test_s3, 'x_test_s3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
